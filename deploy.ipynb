{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HF model_idë¡œ ë¶€í„° ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma3-s3-vllm-async-2025-08-13-10-48-23-372\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import Model\n",
    "import sagemaker, boto3\n",
    "\n",
    "region = \"us-west-2\"\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "# LMI v15 (vLLM) ì»¨í…Œì´ë„ˆ URI (ë²„ì „ì€ ì˜ˆì‹œ)\n",
    "container_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.33.0-lmi15.0.0-cu128\"\n",
    "\n",
    "\n",
    "# vLLM Async ëª¨ë“œ(ê¶Œì¥). LoRAê°€ í•„ìš” ì—†ë‹¤ë©´ ì„±ëŠ¥/ì•ˆì •ì„± ì¢‹ìŒ\n",
    "env = {\n",
    "    \"HF_MODEL_ID\": model_id,\n",
    "    # \"HF_MODEL_ID\": \"s3://my-model-train/hf_models/gemma-3-4b-it-uncompressed/\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"8192\",\n",
    "    \"SERVING_FAIL_FAST\": \"true\",\n",
    "    \"HF_TOKEN\": HF_TOKEN, # \"<your token>\"\n",
    "}\n",
    "\n",
    "model = Model(image_uri=container_uri, role=role,  env=env)\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"gemma3-s3-vllm-async\")\n",
    "\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.24xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    container_startup_health_check_timeout=500,  # ëŒ€í˜• ëª¨ë¸ ë¡œë”© ì—¬ìœ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-d957dd896621418c84db47e192c5a588\",\"object\":\"chat.completion\",\"created\":1755082754,\"model\":\"lmi\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"reasoning_content\":null,\"content\":\"ê°€ì„ ìº í•‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ ë“œë¦´ê²Œìš”! ğŸ‚ğŸ ê°€ì„ ìº í•‘ì€ ì—¬ë¦„ë§Œí¼ ëœ¨ê²ì§€ ì•Šì§€ë§Œ, ìŒ€ìŒ€í•œ ë‚ ì”¨ì™€ ë³€ë•ìŠ¤ëŸ¬ìš´ ë‚ ì”¨ ë•Œë¬¸ì— ê¼¼ê¼¼í•œ ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤. \\n\\n**1. ìº í•‘ ì¥ë¹„ ì ê²€ ë° ì¤€ë¹„**\\n\\n*   [ ] í…íŠ¸: ë°©ìˆ˜, ë°©í’ ê¸°ëŠ¥ í™•ì¸ ë° íŒ©, ìŠ¤í‹± ë“± ë¶€ì†í’ˆ ì ê²€\\n*   [ ] íƒ€í”„: ë°”ëŒì— ì˜ ë§ëŠ”ì§€, íŒ©ì´ ì˜ ë°•íˆëŠ”ì§€ í™•ì¸\\n*   [ ] í…Œì´ë¸”, ì˜ì: íŠ¼íŠ¼í•œì§€, ìˆ˜ë‚© ê°€ëŠ¥í•œì§€ í™•ì¸\\n*   [ ] ëœí„´, í—¤ë“œëœí„´: ì—¬ë¶„ ë°°í„°ë¦¬ ì¤€ë¹„\\n*   [ ] ë²„ë„ˆ, ì—°ë£Œ: ì‘ë™ í™•ì¸ ë° ì—°ë£Œ ì¶©ë¶„íˆ ì¤€ë¹„\\n*   [ ] ì½”í , ì‹ê¸°, ì¡°ë¦¬ë„êµ¬: ê¹¨ë—í•˜ê²Œ ì„¸ì²™ í›„ ì¤€ë¹„\\n*   [ ] ë³´ê´€í•¨, ìˆ˜ë‚© ê°€ë°©: ì§ ì •ë¦¬ ìš©ì´í•˜ë„ë¡ ì¤€ë¹„\\n*   [ ] ìº í•‘ ë§¤íŠ¸, ì¹¨ë‚­: í…íŠ¸ ì˜¨ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ì¹¨ë‚­ ì„ íƒ\\n*   [ ] ë‚œë°© ìš©í’ˆ (ì„ íƒ): ì „ê¸°íˆí„°, ë³´\",\"tool_calls\":[]},\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":18,\"total_tokens\":274,\"completion_tokens\":256,\"prompt_tokens_details\":null},\"prompt_logprobs\":null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3, json\n",
    "smr = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "body = {\n",
    "  \"messages\":[{\"role\":\"user\",\"content\":\"ê°€ì„ ìº í•‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´ì¤˜\"}],\n",
    "  \"max_tokens\":256,\n",
    "  \"temperature\":0.7,\n",
    "  \"stream\":False\n",
    "}\n",
    "\n",
    "resp = smr.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(body),\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "print(resp[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3ë¡œ ë¶€í„° ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance_type = \"ml.p4d.24xlarge\"\n",
    "instance_type = \"ml.g6.24xlarge\"\n",
    "# instance_type = \"ml.g5.24xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "gemma3-s3-vllm-async-2025-08-14-02-10-03-005\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import Model\n",
    "import sagemaker, boto3\n",
    "\n",
    "region = \"us-west-2\"\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "# LMI v15 (vLLM) ì»¨í…Œì´ë„ˆ URI (ë²„ì „ì€ ì˜ˆì‹œ)\n",
    "container_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.33.0-lmi15.0.0-cu128\" # Nvidia Driver 550ì„ ìš”êµ¬ (p5ê³„ì—´)\n",
    "# container_uri = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.31.0-lmi13.0.0-cu124-v1.0\"\n",
    "\n",
    "\n",
    "\n",
    "s3_uri = \"s3://my-model-train/hf_models/gemma-3-4b-it-uncompressed/\"\n",
    "\n",
    "# # S3 prefix(ëì— /) ì•„ë˜ì— config.json, *.safetensors, tokenizer.* ë“±ì´ ê·¸ëŒ€ë¡œ ìˆëŠ” ìƒíƒœ\n",
    "# model_data = {\n",
    "#     \"S3DataSource\": {\n",
    "#         \"S3Uri\": \"s3://my-model-train/hf_models/gemma-3-4b-it-uncompressed/\",  # ë³‘í•© ëª¨ë¸ì´ë¼ë©´ ì´ ê²½ë¡œ\n",
    "#         \"S3DataType\": \"S3Prefix\",\n",
    "#         \"CompressionType\": \"None\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# vLLM Async ëª¨ë“œ(ê¶Œì¥). LoRAê°€ í•„ìš” ì—†ë‹¤ë©´ ì„±ëŠ¥/ì•ˆì •ì„± ì¢‹ìŒ\n",
    "env = {\n",
    "    \"HF_MODEL_ID\": s3_uri,\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    # \"OPTION_ROLLING_BATCH\": \"vllm\",\n",
    "    # \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"8\",\n",
    "    # \"OPTION_MODEL_IMPL\": \"transformers\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"OPTION_DTYPE\": \"auto\",  #\"bfloat16\",\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"4096\",\n",
    "    \"SERVING_FAIL_FAST\": \"true\",\n",
    "    \"OPTION_GPU_MEMORY_UTILIZATION\": \"0.75\",\n",
    "    \"OPTION_SWAP_SPACE\": \"4\",\n",
    "    # í•„ìš” ì‹œ ì»¤ìŠ¤í…€ ëª¨ë¸ íŒŒì¼ì´ ìˆìœ¼ë©´:\n",
    "    # \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "}\n",
    "\n",
    "# env = {\n",
    "#     \"HF_MODEL_ID\": s3_uri,\n",
    "#     \"OPTION_ROLLING_BATCH\": \"vllm\",\n",
    "#     \"OPTION_DTYPE\": \"auto\",\n",
    "#     \"OPTION_GPU_MEMORY_UTILIZATION\": \"0.8\",      # 0.7ì—ì„œ 0.6ìœ¼ë¡œ ê°ì†Œ\n",
    "#     \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"4\",        # 8ì—ì„œ 4ë¡œ ê°ì†Œ\n",
    "#     \"OPTION_MAX_NUM_BATCHED_TOKENS\": \"1024\",      # 512ì—ì„œ 256ìœ¼ë¡œ ê°ì†Œ\n",
    "#     \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",        # max ëŒ€ì‹  ëª…ì‹œì ìœ¼ë¡œ 4\n",
    "#     \"OPTION_MAX_MODEL_LEN\": \"512\",              # 512ì—ì„œ 1024ë¡œ ì¦ê°€\n",
    "#     \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "#     \"OPTION_ASYNC_MODE\": \"true\",\n",
    "#     # \"OPTION_PREEMPTION_MODE\": \"swap\",\n",
    "#     \"OPTION_SWAP_SPACE\": \"16\",\n",
    "#     \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "# }\n",
    "\n",
    "# model = Model(image_uri=container_uri, role=role, model_data=model_data, env=env)\n",
    "model = Model(image_uri=container_uri, role=role,  env=env)\n",
    "endpoint_name_s3 = sagemaker.utils.name_from_base(\"gemma3-s3-vllm-async\")\n",
    "\n",
    "print(endpoint_name_s3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name_s3,\n",
    "    container_startup_health_check_timeout=500,  # ëŒ€í˜• ëª¨ë¸ ë¡œë”© ì—¬ìœ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-62ee558c6dc94e7f9158a9fa553b4ffe\",\"object\":\"chat.completion\",\"created\":1755137979,\"model\":\"lmi\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"reasoning_content\":null,\"content\":\"ê°€ì„ ìº í•‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ ë“œë¦´ê²Œìš”! ê°€ì„ ìº í•‘ì€ ì—¬ë¦„ë§Œí¼ ëœ¨ê²ì§€ ì•Šì§€ë§Œ, ë°¤ì—ëŠ” ìŒ€ìŒ€í•´ì§€ê¸° ë•Œë¬¸ì— ê¼¼ê¼¼í•˜ê²Œ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤. \\n\\n**1. ìº í•‘ ì¥ë¹„ ì ê²€ ë° ì¤€ë¹„**\\n\\n*   [ ] í…íŠ¸: ì°¢ì–´ì§, ë§ˆëª¨, ë°©ìˆ˜ ìƒíƒœ í™•ì¸ ë° ë°©ìˆ˜ ìŠ¤í”„ë ˆì´ ë¿Œë¦¬ê¸°\\n*   [ ] íƒ€í”„: ì°¢ì–´ì§, ë§ˆëª¨, ë°©ìˆ˜ ìƒíƒœ í™•ì¸\\n*   [ ] í…Œì´ë¸”, ì˜ì: íŒŒì† ì—¬ë¶€ í™•ì¸, ì´ë™ ë°”êµ¬ë‹ˆ ì¤€ë¹„\\n*   [ ] ëœí„´, í—¤ë“œëœí„´: ë°°í„°ë¦¬ ì¶©ì „ ë° ìƒˆ ë°°í„°ë¦¬ ì¤€ë¹„\\n*   [ ] ë²„ë„ˆ, ì—°ë£Œ: ë²„ë„ˆ ì‘ë™ í™•ì¸, ì—°ë£Œ ì¶©ë¶„íˆ ë³´ì¶©\\n*   [ ] ì½”í , ì‹ê¸°ë¥˜: ì„¸ì²™ ë° ì¤€ë¹„, ì¹¼, ë„ë§ˆ, ì¡°ë¦¬ë„êµ¬\\n*   [ ] ëƒ‰ì¥ê³ /ì¿¨ëŸ¬: ì•„ì´ìŠ¤ë°•ìŠ¤ ì•„ì´ìŠ¤íŒ©/ì–¼ìŒ ì¤€ë¹„\\n*   [ ] ì¹¨ë‚­, ë§¤íŠ¸: ì²­ì†Œ ë° ì ê²€, ë³´ì˜¨ì— ì‹ ê²½ ì“°ê¸°\\n*   [ ] ìº í•‘ ê°€ë°©: ì§ ì •ë¦¬ ë° ì´ë™\",\"tool_calls\":[]},\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":18,\"total_tokens\":274,\"completion_tokens\":256,\"prompt_tokens_details\":null},\"prompt_logprobs\":null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3, json\n",
    "smr = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "body = {\n",
    "  \"messages\":[{\"role\":\"user\",\"content\":\"ê°€ì„ ìº í•‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´ì¤˜\"}],\n",
    "  \"max_tokens\":256,\n",
    "  \"temperature\":0.7,\n",
    "  \"stream\":False\n",
    "}\n",
    "\n",
    "resp = smr.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_s3,\n",
    "    Body=json.dumps(body),\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "print(resp[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
